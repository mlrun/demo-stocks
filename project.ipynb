{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks Analysis Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# MLRun imports\n",
    "from mlrun import mlconf\n",
    "\n",
    "# Setup API Endpoint\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MLRun stocks project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_project\n",
    "\n",
    "# update the dir and repo to reflect real locations \n",
    "# the remote git repo must be initialized in GitHub\n",
    "project_dir = os.path.abspath('./')\n",
    "remote_git = 'https://github.com/mlrun/demo-stocks.git'\n",
    "\n",
    "# Create the project\n",
    "project = new_project('stocks', project_dir, init_git=False)\n",
    "\n",
    "# We can update our project directory to the latest status by running\n",
    "# newproj.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an artifact path to keep track of where our artifacts are going\n",
    "ARTIFACT_PATH =  os.path.join(os.path.abspath(project.context), 'artifacts')\n",
    "mlconf.artifact_path = ARTIFACT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f0814502e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set functions to project\n",
    "project.set_function('code/03-read-stocks.yaml', name='stocks_reader', kind='nuclio')\n",
    "project.set_function('code/04-read-news.yaml', name='news_reader', kind='nuclio')\n",
    "project.set_function('code/05-stream-viewer.yaml', name='stream_viewer', kind='nuclio')\n",
    "project.set_function('code/06-grafana.yaml', name='grafana', kind='job')\n",
    "project.set_function('training/bert_sentiment_classification.yaml', name='bert_sentiment_classifier_trainer', kind='job')\n",
    "project.set_function('hub://sentiment_analysis_serving', name='sentiment_analysis_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io, mlconf\n",
    "import os\n",
    "from nuclio.triggers import V3IOStreamTrigger\n",
    "\n",
    "funcs = {}\n",
    "\n",
    "# Directories and Paths\n",
    "projdir = os.path.join('/', 'User', 'demo-stocks')\n",
    "# model_filepath = os.path.join(projdir, 'models', 'bert_sentiment_analysis_model.pt')\n",
    "model_filepath = os.path.join(projdir, 'models', 'model.pt')\n",
    "reviews_datafile = os.path.join(projdir, 'data', 'reviews.csv')\n",
    "\n",
    "# Performence limit\n",
    "sentiment_server_max_replicas = 1\n",
    "\n",
    "\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        # Add V3IO Mount\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "        # Always pull images to keep updates\n",
    "        f.spec.image_pull_policy = 'Always'\n",
    "    \n",
    "    # Define inference-stream related triggers\n",
    "    functions['sentiment_analysis_server'].add_model('bert_classifier_v1', model_filepath)\n",
    "    functions['sentiment_analysis_server'].spec.readiness_timeout = 500\n",
    "    functions['sentiment_analysis_server'].set_config('readinessTimeoutSeconds', 500)\n",
    "    functions['sentiment_analysis_server'].spec.max_replicas = sentiment_server_max_replicas\n",
    "                \n",
    "        \n",
    "@dsl.pipeline(\n",
    "    name='Stocks demo deployer',\n",
    "    description='Up to RT Stocks ingestion and analysis'\n",
    ")\n",
    "def kfpipeline(\n",
    "    # General\n",
    "    V3IO_CONTAINER = 'bigdata',\n",
    "    STOCKS_TSDB_TABLE = 'stocks/stocks_tsdb',\n",
    "    STOCKS_SENTIMENT_TSDB_TABLE = 'stocks/stocks_sentiment_tsdb',\n",
    "    STOCKS_KV_TABLE = 'stocks/stocks_kv',\n",
    "    STOCKS_STREAM = 'stocks/stocks_stream',\n",
    "    RUN_TRAINER = False,\n",
    "    \n",
    "    # Trainer\n",
    "    pretrained_model = 'bert-base-cased',\n",
    "    reviews_dataset = reviews_datafile,\n",
    "    models_dir = 'models',\n",
    "    model_filename = 'bert_sentiment_analysis_model.pt',\n",
    "    n_classes = 3,\n",
    "    MAX_LEN = 128,\n",
    "    BATCH_SIZE = 16,\n",
    "    EPOCHS =  1,\n",
    "    random_state = 42,\n",
    "    \n",
    "    # stocks reader\n",
    "    STOCK_LIST = ['GOOGL', 'MSFT', 'AMZN', 'AAPL', 'INTC'],\n",
    "    EXPRESSION_TEMPLATE = \"symbol='{symbol}';price={price};volume={volume};last_updated='{last_updated}'\",\n",
    "    \n",
    "    # Sentiment analysis server\n",
    "    model_name = 'bert_classifier_v1',\n",
    "    model_filepath = model_filepath # if not trained\n",
    "    \n",
    "    ):\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == True):\n",
    "        \n",
    "        trainer_image_builder = funcs['bert_sentiment_classifier_trainer'].deploy_step(skip_deployed=True)\n",
    "        \n",
    "        trainer = funcs['bert_sentiment_classifier_trainer'].as_step(name='bert_sentiment_classifier_trainer',\n",
    "                                                                     params={'pretrained_model': pretrained_model,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'models_dir': models_dir,\n",
    "                                                                             'model_filename': model_filename,\n",
    "                                                                             'n_classes': n_classes,\n",
    "                                                                             'MAX_LEN': MAX_LEN,\n",
    "                                                                             'BATCH_SIZE': BATCH_SIZE,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'random_state': random_state},\n",
    "                                                                     inputs={'reviews_dataset': reviews_dataset},\n",
    "                                                                     image=trainer_image_builder.outputs['image'],\n",
    "                                                                     outputs=['bert_sentiment_analysis_model'])\n",
    "        \n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step(env={f'SERVING_MODEL_{model_name}': trainer.outputs['bert_sentiment_analysis_model']})\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                        'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                        'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint']})\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == False):\n",
    "        \n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step(env={f'SERVING_MODEL_{model_name}': model_filepath})\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_SENTIMENT_TSDB_TABLE': STOCKS_SENTIMENT_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint']})\n",
    "    \n",
    "    stocks_reader = funcs['stocks_reader'].deploy_step(env={'STOCK_LIST': STOCK_LIST,\n",
    "                                                            'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'STOCKS_KV_TABLE': STOCKS_KV_TABLE,\n",
    "                                                            'EXPRESSION_TEMPLATE': EXPRESSION_TEMPLATE})\n",
    "    \n",
    "    stream_viewer = funcs['stream_viewer'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM}).after(news_reader)\n",
    "    \n",
    "    grafana_builder = funcs['grafana'].deploy_step(skip_deployed=True)\n",
    "    \n",
    "    grafana_dashboard = funcs['grafana'].as_step(name='grafana_deployer',\n",
    "                                                 params={'streamview_url': stream_viewer.outputs['endpoint'],\n",
    "                                                         'v3io_container': V3IO_CONTAINER,\n",
    "                                                         'stocks_kv_table': STOCKS_KV_TABLE,\n",
    "                                                         'stocks_tsdb_table': STOCKS_TSDB_TABLE,\n",
    "                                                         'stocks_sentiment_tsdb_table': STOCKS_SENTIMENT_TSDB_TABLE,},\n",
    "                                                 image=grafana_builder.outputs['image'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_workflow('main', os.path.join(os.path.abspath(project.context), 'code', 'workflow.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save(os.path.join(project.context, 'project.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-09-24 08:11:51,593 [info] using in-cluster config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Boolean\" based on the value \"False\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"3\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"128\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"16\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"1\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"42\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"['GOOGL', 'MSFT', 'AMZN', 'AAPL', 'INTC']\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.netapp-cvs-demo.iguazio-cd0.com/pipelines/#/experiments/details/7c0326a9-e251-47c5-b4d7-380fe27b2b62\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.netapp-cvs-demo.iguazio-cd0.com/pipelines/#/runs/details/7f811f99-4869-450f-8c3c-893eb1ace4ab\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-09-24 08:11:52,256 [info] Pipeline run id=7f811f99-4869-450f-8c3c-893eb1ace4ab, check UI or DB for progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7f811f99-4869-450f-8c3c-893eb1ace4ab'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.run('main', artifact_path=ARTIFACT_PATH, dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
