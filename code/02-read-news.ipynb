{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape news and Analyse sentiments\n",
    "This notebook shows an example of scraping news articles linked to specific traded companies and utilizing our predeployed sentiment analysis model server to predict the sentiment of the author towards said companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the nuclio-jupyter package is not installed run !pip install nuclio-jupyter\n",
    "import nuclio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio env -c V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "%nuclio env -c V3IO_USERNAME=${V3IO_USERNAME}\n",
    "%nuclio env -c V3IO_API=${V3IO_API}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install beautifulsoup4\n",
    "pip install pandas\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import v3io_frames as v3f\n",
    "from unicodedata import normalize\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_news_page(stock_string):\n",
    "    request = Request('https://www.investing.com/equities/' + stock_string + '-news', headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    content = urlopen(request).read()\n",
    "    return bs(content, 'html.parser')\n",
    "\n",
    "def get_internal_article_links(page):\n",
    "    news = page.find_all('div', attrs={'class': 'mediumTitle1'})[1]\n",
    "    articles = news.find_all('article', attrs={'class': 'js-article-item articleItem'})\n",
    "    return ['https://www.investing.com' + a.find('a').attrs['href'] for a in articles]\n",
    "\n",
    "def get_article_page(article_link):\n",
    "    request = Request(article_link, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    content = urlopen(request).read()\n",
    "    return bs(content, 'html.parser')\n",
    "\n",
    "def clean_paragraph(paragraph):\n",
    "    paragraph = re.sub(r'\\(http\\S+', '', paragraph)\n",
    "    paragraph = re.sub(r'\\([A-Z]+:[A-Z]+\\)', '', paragraph)\n",
    "    paragraph = re.sub(r'[\\n\\t\\s\\']', ' ', paragraph)\n",
    "    return normalize('NFKD', paragraph)    \n",
    "\n",
    "def extract_text(article_page):\n",
    "    text_tag = article_page.find('div', attrs={'class': 'WYSIWYG articlePage'})\n",
    "    paragraphs = text_tag.find_all('p')\n",
    "    text = '\\n'.join([clean_paragraph(p.get_text()) for p in paragraphs[:-1]])\n",
    "    return text\n",
    "\n",
    "def get_publish_time(article_page):\n",
    "    details = article_page.find('meta', attrs={'itemprop': 'dateModified'})\n",
    "    publish_date = details.get_attribute_list('content')[0]\n",
    "    return str(datetime.strptime(publish_date, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "def get_score(paragraph_scores):\n",
    "    return sum([score - 1 for score in paragraph_scores]) / len(paragraph_scores)  \n",
    "\n",
    "def get_article_scores(context, articles, endpoint):\n",
    "    scores = [] \n",
    "    for i, article in enumerate(articles):\n",
    "        context.logger.info(f'getting score for article {i + 1}\\\\{len(articles)}')\n",
    "        event_data = {'instances': article.split('\\n')}\n",
    "        resp = requests.put(endpoint+'/bert_classifier_v1/predict', json=json.dumps(event_data))\n",
    "        scores.append(get_score(json.loads(resp.text)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    # Setup V3IO Client\n",
    "    client = v3f.Client('framesd:8081',container=os.getenv('V3IO_CONTAINER', 'bigdata'))\n",
    "    setattr(context, 'v3c', client)\n",
    "    \n",
    "    # Create stocks stream\n",
    "    setattr(context, 'stocks_stream', os.getenv('STOCKS_STREAM', 'stocks/stocks_stream'))\n",
    "    context.v3c.create(backend='stream', table=context.stocks_stream, if_exists=1)\n",
    "    \n",
    "    # Create TSDB table\n",
    "    setattr(context, 'stocks_tsdb', os.getenv('STOCKS_SENTIMENT_TSDB_TABLE', 'stocks/stocks_sentiment_tsdb'))\n",
    "    context.v3c.create(backend='tsdb', table=context.stocks_tsdb, rate='1/s', if_exists=1)\n",
    "    \n",
    "    # Supply the endpoint provided at the end of execution of 00-deploy-sentiment-model.ipynb.\n",
    "    setattr(context, 'sentiment_model_endpoint', os.getenv('SENTIMENT_MODEL_ENDPOINT', 'http://nuclio-stocks-sentiment-analysis-serving:8080'))\n",
    "\n",
    "    sym_to_url={'GOOGL': 'google-inc', 'MSFT': 'microsoft-corp', 'AMZN': 'amazon-com-inc', 'AAPL': 'apple-computer-inc'}\n",
    "    setattr(context,'sym_to_url', sym_to_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, handler):\n",
    "    \n",
    "    syms = []\n",
    "    contents = []\n",
    "    links = []\n",
    "    times = []\n",
    "    sentiments = []\n",
    "    \n",
    "    for sym, url_string in context.sym_to_url.items():\n",
    "        context.logger.info(f'Getting news about {sym}')\n",
    "        news_page = get_stock_news_page(url_string)\n",
    "        article_links = get_internal_article_links(news_page)\n",
    "        article_pages = [get_article_page(link) for link in article_links]\n",
    "        articles = [extract_text(article_page) for article_page in article_pages]\n",
    "        curr_sentiments = get_article_scores(context, articles, context.sentiment_model_endpoint)\n",
    "        curr_times = [get_publish_time(article_page) for article_page in article_pages]\n",
    "        \n",
    "        sentiments += curr_sentiments\n",
    "        times += curr_times\n",
    "        for article, link, sentiment, time in zip(articles, article_links, curr_sentiments, curr_times):\n",
    "            record = {\n",
    "                'content': article,\n",
    "                'time': time,\n",
    "                'symbol': sym,\n",
    "                'link': link,\n",
    "                'sentiment': sentiment\n",
    "            }\n",
    "            context.v3c.execute('stream', context.stocks_stream, 'put', args={'data': json.dumps(record)})\n",
    "            \n",
    "            syms.append(sym)\n",
    "            contents.append(article)\n",
    "            links.append(link)\n",
    "                  \n",
    "    if len(sentiments)>0:\n",
    "        df = pd.DataFrame.from_dict({'sentiment': sentiments,\n",
    "                                     'time': times,\n",
    "                                     'symbol': syms})\n",
    "        df = df.set_index(['time', 'symbol'])\n",
    "        df.index = df.index.set_levels([pd.to_datetime(df.index.levels[0]), df.index.levels[1]])\n",
    "        df = df.sort_index(level=0, axis=0)\n",
    "        context.logger.debug_with('writing data to TSDB', df=df)\n",
    "        context.v3c.write(backend='tsdb', table=context.stocks_tsdb, dfs=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuclio import Event\n",
    "event = Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2020-09-27 16:43:43,538 [info] Getting news about GOOGL\n",
      "Python> 2020-09-27 16:43:48,937 [info] getting score for article 1\\5\n",
      "Python> 2020-09-27 16:43:49,249 [info] getting score for article 2\\5\n",
      "Python> 2020-09-27 16:43:49,644 [info] getting score for article 3\\5\n",
      "Python> 2020-09-27 16:43:49,960 [info] getting score for article 4\\5\n",
      "Python> 2020-09-27 16:43:50,234 [info] getting score for article 5\\5\n",
      "Python> 2020-09-27 16:43:50,535 [info] Getting news about MSFT\n",
      "Python> 2020-09-27 16:43:57,724 [info] getting score for article 1\\7\n",
      "Python> 2020-09-27 16:43:58,010 [info] getting score for article 2\\7\n",
      "Python> 2020-09-27 16:43:58,286 [info] getting score for article 3\\7\n",
      "Python> 2020-09-27 16:43:58,448 [info] getting score for article 4\\7\n",
      "Python> 2020-09-27 16:43:58,900 [info] getting score for article 5\\7\n",
      "Python> 2020-09-27 16:43:59,234 [info] getting score for article 6\\7\n",
      "Python> 2020-09-27 16:43:59,328 [info] getting score for article 7\\7\n",
      "Python> 2020-09-27 16:43:59,478 [info] Getting news about AMZN\n",
      "Python> 2020-09-27 16:44:03,834 [info] getting score for article 1\\3\n",
      "Python> 2020-09-27 16:44:04,245 [info] getting score for article 2\\3\n",
      "Python> 2020-09-27 16:44:04,837 [info] getting score for article 3\\3\n",
      "Python> 2020-09-27 16:44:05,076 [info] Getting news about AAPL\n",
      "Python> 2020-09-27 16:44:11,708 [info] getting score for article 1\\6\n",
      "Python> 2020-09-27 16:44:11,958 [info] getting score for article 2\\6\n",
      "Python> 2020-09-27 16:44:12,223 [info] getting score for article 3\\6\n",
      "Python> 2020-09-27 16:44:12,734 [info] getting score for article 4\\6\n",
      "Python> 2020-09-27 16:44:13,078 [info] getting score for article 5\\6\n",
      "Python> 2020-09-27 16:44:13,290 [info] getting score for article 6\\6\n"
     ]
    }
   ],
   "source": [
    "handler(context, event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-09-27 16:43:03,238 [info] function spec saved to path: 04-read-news.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fb2aabff350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function\n",
    "\n",
    "environment_variables = {'V3IO_CONTAINER': 'bigdata',\n",
    "                         'STOCKS_STREAM': 'stocks/stocks_stream',\n",
    "                         'SENTIMENT_MODEL_ENDPOINT': 'http://nuclio-stocks-sentiment-analysis-serving:8080'}\n",
    "\n",
    "fn = code_to_function('read-news',\n",
    "                      kind='nuclio',\n",
    "                      handler='handler')\n",
    "fn.add_trigger('cron', nuclio.triggers.CronTrigger(interval='300s'))\n",
    "fn.export('02-read-news.yaml')\n",
    "fn.set_envs(environment_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-09-27 16:43:03,250 [info] deploy started\n",
      "[nuclio] 2020-09-27 16:43:09,382 (info) Build complete\n",
      "[nuclio] 2020-09-27 16:43:13,424 (info) Function deploy complete\n",
      "[nuclio] 2020-09-27 16:43:13,433 done updating stocks-read-news, function address: 3.12.231.36:32019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://3.12.231.36:32019'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.deploy(project='stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
